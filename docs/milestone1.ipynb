{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"6c414fad17b448f891f8f1c2035d2aaf","deepnote_cell_type":"text-cell-h1","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["# Project Design Outline (MS1)"]},{"cell_type":"markdown","metadata":{"cell_id":"839bf5e792574cacade8969c7784abc8","deepnote_cell_type":"markdown","tags":[]},"source":["Team39: Philipp Arens, Ben Ray, Andy Zhuo"]},{"cell_type":"markdown","metadata":{"cell_id":"a4617454b79d4eb3b9fa65a91b991a73","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"cell_id":"0301b1db8a9d42fda5bf856583da87ce","deepnote_cell_type":"markdown","tags":[]},"source":["Derivatives play an essential role in many areas of science and engineering such as fluid dynamics, solving ODEs, optimization and - relatedly - machine learning. In general, there exist four main ways of computing derivatives in practice, that is: manual computation (i.e. computing and implementing derivatives by hand), symbolic differentiation (i.e. WolframAlpha or SymPy), numerical differentiation (i.e. finite difference method) and automatic differentiation (AD). Depending on the complexity of the target function, manual differentiation can require significant amounts of time and is often challenging to \"debug\". Symbolic differentiation alleviates this at the expense of potentially bloated/unitutitive expressions. If analytic derivative expressions are not needed, numerical differentiation, that is approximating derivatives through finite differences, could be considered. This, however, can lead to approximation/floating point errors if the step size is chosen inadequately. \n","\n","AD has emerged as a promising way of adressing many of these issues. Though not providing closed form/symbolic expressions, it allows us to compute derivatives with machine precision without introducing large computational overhead. Sparked by recent advances in machine learning, in particular deep neural networks, which use a subclass of AD (i.e. the backpropagation algorithm) in their training phase, AD has shown its potential across a variety of different aplications.\n","\n","In this project we aim at developing a software package implementing a subclass of AD, namely forward mode AD. We aim at making this software intuitive to use, following best practices in terms of relying on the python data model and style guides."]},{"cell_type":"markdown","metadata":{"cell_id":"e6ff2866b07a49a49c4aa5190f74fee5","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Background"]},{"cell_type":"markdown","metadata":{"cell_id":"736eab9e586e40a1b5ba3ffbd1489d79","deepnote_cell_type":"markdown","tags":[]},"source":["Central to automatic differentiation (AD) is use of the chain rule to decompose derivatives into elemtary binary operations (+, -, *, /, **) and unary operations (sin, cos, exp, log, etc.) Using the chain rule allows for two modes of evaluating a derivative:\n","\n","1. Forward mode AD - the derivative is computed \"bottom up\" (i.e. fixing the independent variable(s), take the derivative of the innermost function first, and then move up taking derivatives of each sub-expression recursively)\n","2. Reverse mode AD - the derivative is computed \"top down\" (i.e. you fix the dependent variable, take the derivative of the outermost function first with respect to its sub-expressions, and then move inwards taking successive derivatives with respect to their inner sub-expressions).\n","\n","AD can be generalized to both oridinary and partial derivatives using matrix products of Jacobians.\n","\n","Finally, in forward mode AD, we commonly redefine our arithmetic to use dual numbers of the form $x + x'\\epsilon$ where $\\epsilon$ is a mathematical object not contained in the set of real numbers, with the property $\\epsilon^2 = 0$. This allows us to store the decomposed derivative as a computational graph represented by dual numbers in each node. Despite this abstract implementation, we can still preserve the critical concept of \"duck typing\": as long as our dual numbers act like an input to their function (e.g. they can be added, multiplied, etc.) then the function will work."]},{"cell_type":"markdown","metadata":{"cell_id":"4448ee8aec0b4576b64fc2393549304d","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## How to use `ad39`"]},{"cell_type":"markdown","metadata":{"cell_id":"ac54f963d4df422f97719eb60cd296f3","deepnote_cell_type":"markdown","tags":[]},"source":["Users will be able to install our package from the Test PyPi server using pip. Users will also have to `pip install numpy` (and maybe `pip install matplotlib` depending on our extension) - the packages that `ad39` is dependent on. Having installed the package, users will be able to call `import ad39` before using the package to its full effect.\n","\n","The following provides a summary of how users will be able to perform automatic differentiation with the `ad39` package:\n","\n","- Instantiate all input variables to your function as nodes:\n","e.g. given $f(x_1, x_2) = x_1 + x_2$, instantiate `x1 = Node()` and `x2 = Node()`\n","- Write the function you wish to differentiate in terms of its node inputs\n","e.g. `def f(x1, x2):\n","        return x1 + x2`\n","- Instantiate an object for performing AD:\n","e.g. `AD = AD(f)`\n","- Call the forward mode method on the AD object, passing the input values (and, optionally if not one-hot vectors, the seed vector) at which you wish to evaluate the function and its derivative:\n","e.g. calling `AD.forward_mode(x1=1, x2=1, seed=None)` will return a tuple of $f(1, 1)$ and $f'(1, 1)$\n","\n","In summary, using the `ad39` package to perform forward mode will look something like the following:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install package\n","python3 -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/ ad39\n","\n","# Import package\n","import ad39\n","\n","# Instantiate nodes\n","x1 = Node()\n","x2 = Node()\n","\n","# Write function you wish to differentiate in terms of its node inputs\n","def f(x1, x2):\n","    return x1 + x2\n","\n","# Instantiate an object for performing AD\n","AD = AD(f)\n","\n","# Perform forward mode AD\n","result = AD.forward_mode(x1=1, x2=1, seed=None) # returns a tuple of $f(1, 1)$ and $f'(1, 1)$"]},{"cell_type":"markdown","metadata":{"cell_id":"42ceefb1b9654bc3ad8162196526f9be","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Software Organization"]},{"cell_type":"markdown","metadata":{"cell_id":"68d69206c88f45e0b3a8b975a0125225","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":9,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Structure"]},{"cell_type":"markdown","metadata":{"cell_id":"9f50ca4926514df6ba2e4ca6e7cbbc9d","deepnote_cell_type":"markdown","tags":[]},"source":["    project\n","        ├── LICENSE\n","        ├── README.md\n","        ├── docs\n","        ├── project.toml\n","        ├── setup.cfg\n","        ├── src\n","        │   └── ad39_package\n","        │       ├── __init__.py\n","        │       ├── core.py\n","        │       └── helpers.py   \n","        └── tests\n","            ├── run_tests.sh\n","            ├── test_core.py\n","            └── test_helpers.py"]},{"cell_type":"markdown","metadata":{"cell_id":"d770bedff86c487b9306ee5fa511b609","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":7,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Modules"]},{"cell_type":"markdown","metadata":{"cell_id":"36039419db824b74abf088d93a948b31","deepnote_cell_type":"markdown","tags":[]},"source":["Most of the file tree is self explanatory, but to briefly explain the contents of the `ad39_package`:\n","- `__init__.py` will initialize the entire package.\n","- `core.py` contains the main classes for AD like the `Node` and `ForwardMode` classes (defined below)\n","- `helpers.py` contains potential helper functions or classes as (e.g. a `DualNumbers` class)\n","\n","We may choose to include additional modules as the project grows."]},{"cell_type":"markdown","metadata":{"cell_id":"00a8e6d3f93b4b6581ff62379fc4dc2d","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":5,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Tests"]},{"cell_type":"markdown","metadata":{"cell_id":"585d34cb2c424a58b3ae2d283b3153c2","deepnote_cell_type":"markdown","tags":[]},"source":["Our test suite will live in a designated `test` directory on the root level of the main `project` directory. We envision this to include a test of the main features as well as a test of the additional features of our AD package."]},{"cell_type":"markdown","metadata":{"cell_id":"3eb1244b16e847f28915ecdcacf0ae2b","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":20,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Package Distribution"]},{"cell_type":"markdown","metadata":{"cell_id":"62e012c9c9df4c0f994e221d2916cd94","deepnote_cell_type":"markdown","tags":[]},"source":["We plan to distribute our package using PyPI (i.e PEP517/518). To this end we would use the PyPI Test server and resolve extra dependencies from the main server with the `--extra-index-url` flag."]},{"cell_type":"markdown","metadata":{"cell_id":"449abb8d65984793ad541235b624beb6","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## Implementation"]},{"cell_type":"markdown","metadata":{"cell_id":"f5d15789-0999-422c-97c3-d0a50aa3a58c","checked":false,"deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":20,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Core Data Structures"]},{"cell_type":"markdown","metadata":{"cell_id":"a599d50fdf9f4fae9777ee4574b590db","deepnote_cell_type":"markdown","tags":[]},"source":["Our implementation of AD relies on a directed computational graph represented as a set of instantiated Node objects. Each instance of the Node class will store, upon initialization, \n","1. `op` - an elementary operation to be performed on the intermediate variable(s) passed into the node.\n","2. `deriv` - the derivative expression corresponding to `op`, constructed via a helper function.\n","3. `parent` - an array of at most 2 previous nodes, containing the intermediate variable(s) passed as arguments to this node's `op`.\n","4. `val` - the function's value evaluated at this step in the computation, initialized as `None` until an input is provided in a call to `ForwardMode`.\n","5. `derival` - the function's derivative evaluated at this step in the computation, initialized as `None` until an input is provided in a call to `ForwardMode`.\n","\n","The use of a digraph data structure will allow us to quickly traverse through each intermediate operation when executing forward mode, and the storage of both a function and its derivative in each corresponding node enables the chain rule to be more easily applied upon the evaluation of the elementary operations. While a computational graph is not entirely necessary for the implementation of forward mode, as we have the naive alternative of using dual numbers, constructing a graph will provide great utility in later stages, especially for extensions such as implementing reverse mode or visualizing the computational graph."]},{"cell_type":"markdown","metadata":{"cell_id":"310b467b2d80471091abe6a35a6a3cae","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":22,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Classes and Attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4e63651429f34c14a6ffe4c5f784db22","deepnote_cell_type":"markdown","tags":[]},"outputs":[],"source":["class Node:\n","\n","    def __init__(self, **kwargs):\n","        self.op = kwargs['op']\n","        self.deriv = grad(self.op, self.args)\n","        self.parent = kwargs['parent']\n","        self.val = None\n","        self.derival = None\n","\n","    # For any unary operator (e.g. trig, negation, sqrt, etc.)\n","    # Replace `unop` with name of operator\n","    def unop(self):\n","        next_node = Node('unop', [self])\n","        return next_node\n","        self.next = next_node\n","\n","    # For any binary dunder operator (e.g. add, minus, divide, multiply, etc.)\n","    # Replace `binop` with name of operator and `name` with new operator name\n","    def __binop__(self, other):\n","        next_node = Node(name, op = 'binop', parent = [self, other])\n","        return next_node\n","        self.next = next_node\n","\n","class AD:\n","    \"\"\" AD class contains core functionality for permorming forward mode AD, calculating the gradient, and extension functionality like (maybe) drawing the computational graph \"\"\"\n","\n","    def __init__(self, f):\n","        self.nodes = # self.nodes will be a list of nodes or Tree of nodes\n","        pass\n","\n","    # Computes forward mode AD\n","    def forward_mode(self, seed = None, **kwargs):\n","        pass\n","    \n","    # Constructs the gradient of the intermediate function given the provided arguments\n","    def grad(self, node):\n","        pass\n","\n","    # For example\n","    def draw(self):\n","        pass"]},{"cell_type":"markdown","metadata":{"cell_id":"7c045db3047448fd8926aeaa4f5ebad6","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":19,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### Operator Overloading"]},{"cell_type":"markdown","metadata":{"cell_id":"290632d67d6e45a19bf5b5d9972d99ba","deepnote_cell_type":"markdown","tags":[]},"source":["*Graph Implementation*\n","\n","For the graph implementation of forward mode, and to allow for a potential reverse mode extension, each node in the graph represents an intermediate variable, defined as an output of an operator `op` executed on a set of arguments `parent` from the parent node(s). In order to construct the computational graph for all nodes, we will overload operators such that when the user inputs the function, each operator present in the function will instantiate a new Node storing the operation, and the sub-expression(s) stored as argument(s). The overload template, displayed in the previous section, is different for unary operators, which will be defined in the `Node` class (e.g. def sin(self)), and for binary operators, which will be redefined dunder methods in the Node class (e.g. def \\_\\_add\\_\\_(self, other)).\n","\n","*Dual Numbers*\n","\n","At this stage, we are still considering instantiating a separate means for performing forward mode AD using dual numbers, and reserving the `Node` class for an extension in which we display the computational graph. If our choice of extension resulted in us using dual numbers (as well as nodes), we would overload the operators in a `DualNumber` class. As the chain rule holds for dual numbers we know that for $f(z) = f(a + b \\epsilon) = f(a) + f'(a)b \\epsilon$. For example if we wanted to implement $sin(z)$ where $z$ is a dual number we would have to overload the sin operator to return a new `DualNumber` object with the real component $sin(a)$ and the dual component $cos(a) b$. This will need to be implemented for every operator we plan to support in our library."]},{"cell_type":"markdown","metadata":{"cell_id":"768c5e61797f4ad89e22a4c1abe68666","deepnote_cell_type":"text-cell-h3","formattedRanges":[{"fromCodePoint":0,"marks":{"underline":true},"toCodePoint":18,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["### External Libraries"]},{"cell_type":"markdown","metadata":{"cell_id":"31daf34c749643469768b673524d3b1e","deepnote_cell_type":"markdown","tags":[]},"source":["- NumPy\n","- Matplotlib.pyplot (if we include graph functionality)"]},{"cell_type":"markdown","metadata":{"cell_id":"2215ac97033e4bb48f0a9c07ca8e5cf3","deepnote_cell_type":"text-cell-h2","formattedRanges":[],"is_collapsed":false,"tags":[]},"source":["## License"]},{"cell_type":"markdown","metadata":{"cell_id":"5b46f0c2a8d241ecb70e8b4d27d55bf6","deepnote_cell_type":"markdown","tags":[]},"source":["We decided to go with an MIT (i.e. copyright) license as it permits reuse within proprietary software, provided that all copies of the software or its substantial portions include a copy of the terms of the MIT License and also our original copyright notice. Since we do not hope to commercialize this project, we are happy for others to use it. However, we feel that including the original copyright notice in all derived projects is important, so that future developers understand that the `ad39` package was designed as an educational project (and not more than that), i.e. we want to set developers' expectations for using the `ad39` package by telling them the provenance of the package."]},{"cell_type":"markdown","metadata":{},"source":["## Feedback"]},{"cell_type":"markdown","metadata":{},"source":["### Milestone 1\n","- Background\n","    - We explained the difference between forward and reverse node as computing the derivative \"bottom up\" and \"top down\" rather than \"from the inside out\" and \"from the outside in\", given the intuition that expressions can be thought of as syntax trees.\n","    - We clarified that $\\epsilon$ is a mathematical object not contained in the set of real numbers, to clarify what we had previously described as an \"abstract number\".\n","\n","- How To Use\n","    - Summarized usage in a code snippet.\n","    - Changed how you initialized variables as nodes, removing the need for providing a name to the node (which could conflict across variables): i.e. before you initialized as follows `x1 = Node(\"x1\")`, now it is just `x1 = Node()`.\n","\n","- Software Organization\n","    - Added a note that we may need more modules in `ad39_package` as the project grows.\n","\n","- Implementation\n","    - Removed `node.child` from our implementation of the `Node` class following feedback that \"as long as each node keeps reference of its parent(s), you can access the whole graph with the output nodes as a handle.\" Also removed `node.name` as per earlier feedback - this is no longer necessary, and if we ever need to give a unique ID to nodes, it will be done entirely on the backend.\n","    - Removed the unintuitive `ForwardMode` class, and instead defined an `AD` class, which now includes: (1) a new `forward_mode` method, (2) the `grad` method (moved from the `Node` class to here, but no longer a static method), and (3) any other methods that will be included in our extension, e.g. `draw` for drawing the computational graph. Note, that the `AD` class object is initialized with the function on which AD will be performed, and we may use a further `Tree` class (or just a list of `Node` objects) under the hood to store the nodes created during the computation."]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=91322482-c0b3-4cf4-b2f2-3cb2acdb509e' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"96f4541e901f4d3ea92a5c63f4db6d0d","kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":0}
